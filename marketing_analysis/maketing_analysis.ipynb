{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7313cf1-fa04-4212-8c37-c543f6a24d58",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6934f0a7-95a8-40c4-8599-a07fe8570289",
   "metadata": {},
   "source": [
    "visits = pd.read_csv('datasets/visits_info_short.csv', parse_dates=['Session Start'])\n",
    "orders = pd.read_csv('datasets/orders_info_short.csv', parse_dates=['Event Dt'])\n",
    "costs = pd.read_csv('datasets/costs_info_short.csv', parse_dates=['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd5866-8cd9-4f7c-b2a4-3325af107e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculator.calculator import MetricCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d12a1e-e4f6-498d-9385-661f154913e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = MetricCalculator('datasets/visits_info_short.csv', 'datasets/orders_info_short.csv', 'datasets/costs_info_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af3de4-6261-4bf0-accf-3b56600182a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc.columns_fixer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61793b77-653d-46fd-8c27-dc4807ff5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7ecd0-264b-4171-a1b3-741e9250288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_date = datetime(2020, 1, 1).date()  # момент анализа\n",
    "horizon_days = 7  # горизонт анализа "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d6603-ec63-42cf-a60a-f7a6f8d1084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = calc.get_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13cdd1-58fa-4894-8d14-a0dcd3f0e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc.costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ce19b-5679-4c83-81a8-14bcd90c5733",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4974f-e7ca-4132-a33b-9d4716c4761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_raw, result_grouped, result_in_time = calc.get_retention(profiles, observation_date, horizon_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea594b-328a-4322-91cd-9b47df234b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc.plot_retention(result_grouped, result_in_time, horizon_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e10835-eed3-4569-9e1b-b0e2e725f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5356f2c-2fcf-4d06-8aec-67f9db188f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24887e-6b4a-4e1c-81e7-ff86bfc871c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6ac11-437c-4b15-8f14-b86ed55bf643",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_raw, result_grouped, result_in_time = calc.get_conversion(profiles, observation_date, horizon_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0e9e9-0c57-41d8-a925-39ad0de39d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc.plot_conversion(result_grouped, result_in_time, horizon_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357486f-04c5-42b5-b690-928b0b5310dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd5dd8-4395-46cf-bf48-f03df424a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fadb3-080e-413a-830f-e4cfe7cfe293",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c291b40-e456-439a-aa84-3fd75d210f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_raw, result_grouped, result_in_time, roi_grouped, roi_in_time = calc.get_ltv(profiles, observation_date, horizon_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a86221-0a07-4719-ab4e-ba312d0fea70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c66c70-0448-4427-b1df-14b7069471f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4484c6-1dce-4fa8-a450-d8a43e266614",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b97c8-3c6c-4c43-a1b3-fc0fbaead8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464e60f-a553-4d2f-bf89-1c482d12da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc548d-d3d7-4605-ae36-06e465759ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d552e-a3ed-481c-ab09-9fd89f4f79a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e09ba0-62a8-434f-a49d-04a802cd3c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ef5c6-3cfb-45f3-98f0-5ab68c11b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для создания пользовательских профилей\n",
    "\n",
    "def get_profiles(sessions, orders, events, ad_costs, event_names=[]):\n",
    "\n",
    "    # находим параметры первых посещений\n",
    "    profiles = (\n",
    "        sessions.sort_values(by=['user_id', 'session_start'])\n",
    "        .groupby('user_id')\n",
    "        .agg(\n",
    "            {\n",
    "                'session_start': 'first',\n",
    "                'channel': 'first',\n",
    "                'device': 'first',\n",
    "                'region': 'first',\n",
    "            }\n",
    "        )\n",
    "        .rename(columns={'session_start': 'first_ts'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # для когортного анализа определяем дату первого посещения\n",
    "    # и первый день месяца, в который это посещение произошло\n",
    "    profiles['dt'] = profiles['first_ts'].dt.date\n",
    "    profiles['month'] = profiles['first_ts'].astype('datetime64[M]')\n",
    "\n",
    "    # добавляем признак платящих пользователей\n",
    "    profiles['payer'] = profiles['user_id'].isin(orders['user_id'].unique())\n",
    "\n",
    "    # добавляем флаги для всех событий из event_names\n",
    "    for event in event_names:\n",
    "        if event in events['event_name'].unique():\n",
    "            profiles[event] = profiles['user_id'].isin(\n",
    "                events.query('event_name == @event')['user_id'].unique()\n",
    "            )\n",
    "\n",
    "    # считаем количество уникальных пользователей\n",
    "    # с одинаковыми источником и датой привлечения\n",
    "    new_users = (\n",
    "        profiles.groupby(['dt', 'channel'])\n",
    "        .agg({'user_id': 'nunique'})\n",
    "        .rename(columns={'user_id': 'unique_users'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # объединяем траты на рекламу и число привлечённых пользователей\n",
    "    ad_costs = ad_costs.merge(new_users, on=['dt', 'channel'], how='left')\n",
    "\n",
    "    # делим рекламные расходы на число привлечённых пользователей\n",
    "    ad_costs['acquisition_cost'] = ad_costs['costs'] / ad_costs['unique_users']\n",
    "\n",
    "    # добавляем стоимость привлечения в профили\n",
    "    profiles = profiles.merge(\n",
    "        ad_costs[['dt', 'channel', 'acquisition_cost']],\n",
    "        on=['dt', 'channel'],\n",
    "        how='left',\n",
    "    )\n",
    "\n",
    "    # стоимость привлечения органических пользователей равна нулю\n",
    "    profiles['acquisition_cost'] = profiles['acquisition_cost'].fillna(0)\n",
    "\n",
    "    return profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd775d2-cb10-4cfd-a13e-af7eb8e9dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для расчёта удержания\n",
    "\n",
    "def get_retention(\n",
    "    profiles,\n",
    "    sessions,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "# функция для расчёта удержания\n",
    "\n",
    "    # добавляем столбец payer в передаваемый dimensions список\n",
    "    dimensions = ['payer'] + dimensions\n",
    "\n",
    "    # исключаем пользователей, не «доживших» до горизонта анализа\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # собираем «сырые» данные для расчёта удержания\n",
    "    result_raw = result_raw.merge(\n",
    "        sessions[['user_id', 'session_start']], on='user_id', how='left'\n",
    "    )\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['session_start'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "\n",
    "    # функция для группировки таблицы по желаемым признакам\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='user_id', aggfunc='nunique'\n",
    "        )\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "        return result\n",
    "\n",
    "    # получаем таблицу удержания\n",
    "    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)\n",
    "\n",
    "    # получаем таблицу динамики удержания\n",
    "    result_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    # возвращаем обе таблицы и сырые данные\n",
    "    return result_raw, result_grouped, result_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40171b-face-44fb-a75c-ceb989ce3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# функция для расчёта конверсии\n",
    "\n",
    "def get_conversion(\n",
    "    profiles,\n",
    "    purchases,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "# функция для расчёта конверсии\n",
    "    # исключаем пользователей, не «доживших» до горизонта анализа\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # определяем дату и время первой покупки для каждого пользователя\n",
    "    first_purchases = (\n",
    "        purchases.sort_values(by=['user_id', 'event_dt'])\n",
    "        .groupby('user_id')\n",
    "        .agg({'event_dt': 'first'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # добавляем данные о покупках в профили\n",
    "    result_raw = result_raw.merge(\n",
    "        first_purchases[['user_id', 'event_dt']], on='user_id', how='left'\n",
    "    )\n",
    "\n",
    "    # рассчитываем лайфтайм для каждой покупки\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "\n",
    "    # группируем по cohort, если в dimensions ничего нет\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users' \n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # функция для группировки таблицы по желаемым признакам\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='user_id', aggfunc='nunique'\n",
    "        )\n",
    "        result = result.fillna(0).cumsum(axis = 1)\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        # делим каждую «ячейку» в строке на размер когорты\n",
    "        # и получаем conversion rate\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "        return result\n",
    "\n",
    "    # получаем таблицу конверсии\n",
    "    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)\n",
    "\n",
    "    # для таблицы динамики конверсии убираем 'cohort' из dimensions\n",
    "    if 'cohort' in dimensions: \n",
    "        dimensions = []\n",
    "\n",
    "    # получаем таблицу динамики конверсии\n",
    "    result_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    # возвращаем обе таблицы и сырые данные\n",
    "    return result_raw, result_grouped, result_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea314f-9116-4072-b31c-09e91a2c3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для расчёта LTV и ROI\n",
    "\n",
    "def get_ltv(\n",
    "    profiles,\n",
    "    purchases,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # исключаем пользователей, не «доживших» до горизонта анализа\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "    # добавляем данные о покупках в профили\n",
    "    result_raw = result_raw.merge(\n",
    "        purchases[['user_id', 'event_dt', 'revenue']], on='user_id', how='left'\n",
    "    )\n",
    "    # рассчитываем лайфтайм пользователя для каждой покупки\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "    # группируем по cohort, если в dimensions ничего нет\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users'\n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # функция группировки по желаемым признакам\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        # строим «треугольную» таблицу выручки\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='revenue', aggfunc='sum'\n",
    "        )\n",
    "        # находим сумму выручки с накоплением\n",
    "        result = result.fillna(0).cumsum(axis=1)\n",
    "        # вычисляем размеры когорт\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        # объединяем размеры когорт и таблицу выручки\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        # считаем LTV: делим каждую «ячейку» в строке на размер когорты\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        # исключаем все лайфтаймы, превышающие горизонт анализа\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        # восстанавливаем размеры когорт\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # собираем датафрейм с данными пользователей и значениями CAC, \n",
    "        # добавляя параметры из dimensions\n",
    "        cac = df[['user_id', 'acquisition_cost'] + dims].drop_duplicates()\n",
    "\n",
    "        # считаем средний CAC по параметрам из dimensions\n",
    "        cac = (\n",
    "            cac.groupby(dims)\n",
    "            .agg({'acquisition_cost': 'mean'})\n",
    "            .rename(columns={'acquisition_cost': 'cac'})\n",
    "        )\n",
    "\n",
    "        # считаем ROI: делим LTV на CAC\n",
    "        roi = result.div(cac['cac'], axis=0)\n",
    "\n",
    "        # удаляем строки с бесконечным ROI\n",
    "        roi = roi[~roi['cohort_size'].isin([np.inf])]\n",
    "\n",
    "        # восстанавливаем размеры когорт в таблице ROI\n",
    "        roi['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # добавляем CAC в таблицу ROI\n",
    "        roi['cac'] = cac['cac']\n",
    "\n",
    "        # в финальной таблице оставляем размеры когорт, CAC\n",
    "        # и ROI в лайфтаймы, не превышающие горизонт анализа\n",
    "        roi = roi[['cohort_size', 'cac'] + list(range(horizon_days))]\n",
    "\n",
    "        # возвращаем таблицы LTV и ROI\n",
    "        return result, roi\n",
    "\n",
    "    # получаем таблицы LTV и ROI\n",
    "    result_grouped, roi_grouped = group_by_dimensions(\n",
    "        result_raw, dimensions, horizon_days\n",
    "    )\n",
    "\n",
    "    # для таблиц динамики убираем 'cohort' из dimensions\n",
    "    if 'cohort' in dimensions:\n",
    "        dimensions = []\n",
    "\n",
    "    # получаем таблицы динамики LTV и ROI\n",
    "    result_in_time, roi_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        result_raw,  # сырые данные\n",
    "        result_grouped,  # таблица LTV\n",
    "        result_in_time,  # таблица динамики LTV\n",
    "        roi_grouped,  # таблица ROI\n",
    "        roi_in_time,  # таблица динамики ROI\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d121e-dd2c-480d-b896-1d54dbb8c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для сглаживания фрейма\n",
    "\n",
    "def filter_data(df, window):\n",
    "    # для каждого столбца применяем скользящее среднее\n",
    "    for column in df.columns.values:\n",
    "        df[column] = df[column].rolling(window).mean() \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c694bad-ed71-472c-bdde-fc102bc18043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для визуализации удержания\n",
    "\n",
    "def plot_retention(retention, retention_history, horizon, window=7):\n",
    "\n",
    "    # задаём размер сетки для графиков\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # исключаем размеры когорт и удержание первого дня\n",
    "    retention = retention.drop(columns=['cohort_size', 0])\n",
    "    # в таблице динамики оставляем только нужный лайфтайм\n",
    "    retention_history = retention_history.drop(columns=['cohort_size'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "    # если в индексах таблицы удержания только payer,\n",
    "    # добавляем второй признак — cohort\n",
    "    if retention.index.nlevels == 1:\n",
    "        retention['cohort'] = 'All users'\n",
    "        retention = retention.reset_index().set_index(['cohort', 'payer'])\n",
    "\n",
    "    # в таблице графиков — два столбца и две строки, четыре ячейки\n",
    "    # в первой строим кривые удержания платящих пользователей\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    retention.query('payer == True').droplevel('payer').T.plot(\n",
    "        grid=True, ax=ax1\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('Удержание платящих пользователей')\n",
    "\n",
    "    # во второй ячейке строим кривые удержания неплатящих\n",
    "    # вертикальная ось — от графика из первой ячейки\n",
    "    ax2 = plt.subplot(2, 2, 2, sharey=ax1)\n",
    "    retention.query('payer == False').droplevel('payer').T.plot(\n",
    "        grid=True, ax=ax2\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('Удержание неплатящих пользователей')\n",
    "\n",
    "    # в третьей ячейке — динамика удержания платящих\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    # получаем названия столбцов для сводной таблицы\n",
    "    columns = [\n",
    "        name\n",
    "        for name in retention_history.index.names\n",
    "        if name not in ['dt', 'payer']\n",
    "    ]\n",
    "    # фильтруем данные и строим график\n",
    "    filtered_data = retention_history.query('payer == True').pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax3)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title(\n",
    "        'Динамика удержания платящих пользователей на {}-й день'.format(\n",
    "            horizon\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # в чётвертой ячейке — динамика удержания неплатящих\n",
    "    ax4 = plt.subplot(2, 2, 4, sharey=ax3)\n",
    "    # фильтруем данные и строим график\n",
    "    filtered_data = retention_history.query('payer == False').pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax4)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title(\n",
    "        'Динамика удержания неплатящих пользователей на {}-й день'.format(\n",
    "            horizon\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391566ef-30cc-4fbd-9bc5-c2e0e74e65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для визуализации конверсии\n",
    "\n",
    "def plot_conversion(conversion, conversion_history, horizon, window=7):\n",
    "\n",
    "    # задаём размер сетки для графиков\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # исключаем размеры когорт\n",
    "    conversion = conversion.drop(columns=['cohort_size'])\n",
    "    # в таблице динамики оставляем только нужный лайфтайм\n",
    "    conversion_history = conversion_history.drop(columns=['cohort_size'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "    # первый график — кривые конверсии\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    conversion.T.plot(grid=True, ax=ax1)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('Конверсия пользователей')\n",
    "\n",
    "    # второй график — динамика конверсии\n",
    "    ax2 = plt.subplot(1, 2, 2, sharey=ax1)\n",
    "    columns = [\n",
    "        # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "        name for name in conversion_history.index.names if name not in ['dt']\n",
    "    ]\n",
    "    filtered_data = conversion_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax2)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика конверсии пользователей на {}-й день'.format(horizon))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d8bc2b-adde-41ac-8572-f0f7af3a800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для визуализации LTV и ROI\n",
    "\n",
    "def plot_ltv_roi(ltv, ltv_history, roi, roi_history, horizon, window=7):\n",
    "\n",
    "    # задаём сетку отрисовки графиков\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # из таблицы ltv исключаем размеры когорт\n",
    "    ltv = ltv.drop(columns=['cohort_size'])\n",
    "    # в таблице динамики ltv оставляем только нужный лайфтайм\n",
    "    ltv_history = ltv_history.drop(columns=['cohort_size'])[[horizon - 1]]\n",
    "\n",
    "    # стоимость привлечения запишем в отдельный фрейм\n",
    "    cac_history = roi_history[['cac']]\n",
    "\n",
    "    # из таблицы roi исключаем размеры когорт и cac\n",
    "    roi = roi.drop(columns=['cohort_size', 'cac'])\n",
    "    # в таблице динамики roi оставляем только нужный лайфтайм\n",
    "    roi_history = roi_history.drop(columns=['cohort_size', 'cac'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "    # первый график — кривые ltv\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    ltv.T.plot(grid=True, ax=ax1)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('LTV')\n",
    "\n",
    "    # второй график — динамика ltv\n",
    "    ax2 = plt.subplot(2, 3, 2, sharey=ax1)\n",
    "    # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "    columns = [name for name in ltv_history.index.names if name not in ['dt']]\n",
    "    filtered_data = ltv_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax2)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика LTV пользователей на {}-й день'.format(horizon))\n",
    "\n",
    "    # третий график — динамика cac\n",
    "    ax3 = plt.subplot(2, 3, 3, sharey=ax1)\n",
    "    # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "    columns = [name for name in cac_history.index.names if name not in ['dt']]\n",
    "    filtered_data = cac_history.pivot_table(\n",
    "        index='dt', columns=columns, values='cac', aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax3)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика стоимости привлечения пользователей')\n",
    "\n",
    "    # четвёртый график — кривые roi\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    roi.T.plot(grid=True, ax=ax4)\n",
    "    plt.axhline(y=1, color='red', linestyle='--', label='Уровень окупаемости')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('ROI')\n",
    "\n",
    "    # пятый график — динамика roi\n",
    "    ax5 = plt.subplot(2, 3, 5, sharey=ax4)\n",
    "    # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "    columns = [name for name in roi_history.index.names if name not in ['dt']]\n",
    "    filtered_data = roi_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax5)\n",
    "    plt.axhline(y=1, color='red', linestyle='--', label='Уровень окупаемости')\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика ROI пользователей на {}-й день'.format(horizon))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea06e4c-79c3-4f18-b649-3487e6f32adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
